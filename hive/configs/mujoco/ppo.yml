run_name: &run_name 'ppo'
train_steps: 2000000
test_frequency: 10000
test_episodes: 10
max_steps_per_episode: 1000000
stack_size: &stack_size 1
save_dir: 'experiment'
saving_schedule:
  name: 'PeriodicSchedule'
  kwargs:
    off_value: False
    on_value: True
    period: 500000
environment:
  name: 'GymEnv'
  kwargs:
    env_name: 'Hopper-v3'
    
agent:
  name: 'PPOAgent'
  kwargs:
    actor_net:
      name: 'MLPNetwork'
      kwargs: 
        hidden_units: [64, 64]
    critic_net:
      name: 'MLPNetwork'
      kwargs: 
        hidden_units: [64, 64]
    replay_buffer:
      name: 'PPOReplayBuffer'
      kwargs:
        transitions_per_update: 2048
        use_gae: True
        gae_lambda: .95
    actor_optimizer_fn:
      name: 'Adam'
      kwargs:
        lr: .0003
    critic_optimizer_fn:
      name: 'Adam'
      kwargs:
        lr: .0003
    discount_rate: .99
    grad_clip: .5
    clip_coef: .2
    ent_coef: .0
    clip_vloss: True
    vf_coef: .5
    num_epochs_per_update: 10
    normalize_advantages: True
    batch_size: 128
    device: 'cuda'
    id: 'agent'
    init_fn: 
      name: 'orthogonal'

# List of logger configs used.
loggers:
  -
    name: ChompLogger
  -
    name: WandbLogger
    kwargs:
      project: Hive-PPO1
      name: *run_name
      resume: "allow"
      start_method: "fork"
